# BusinessonBot_Task_Assessment
<center> SENTIMENTAL ANALYSIS ON TWEETS DATA </center>

Steps Followed:
1. Imported the necessary Libraries
2. Imported the dataset
3. Preprocessed the data
4. Visualized the dataset
5. Model Fitting 


MODELS USED:
1. Support Vector Machine
2. AdaBoost Classifier
3. Randomforest Classifier
4. DecisionTree Classifier
5. Gaussian Naive Bayes
6. Bagged MultinomialNB
7. XGBoost Classifier


Finally Viewed the Accuracy Matrix For the Fitted Models

![Screenshot_4](https://user-images.githubusercontent.com/69303196/170854848-566e8e97-0fd2-4310-bf2b-31e7e279746e.png)

SUPPORT VECTOR MACHINE :
          Support vector machines are a set of supervised learning methods used for classification, regression and outliers detection. The advantages of support vector machines are: Effective in high dimensional spaces. Still effective in cases where number of dimensions is greater than the number of samples.

ADABOOST CLASSIFIER :
          Adaptive Boosting is a Machine Learning technique used as an Ensemble Method. The common algorithm used with AdaBoost is Decision trees with only 1 split. These trees are also called Decision Stumps.
          
RANDOFOREST CLASSIFIER :
          The random forest is a classification algorithm consisting of many decisions trees. It uses bagging and feature randomness when building each individual tree to try to create an uncorrelated forest of trees whose prediction by committee is more accurate than that of any individual tree.
          
DECISIONTREE CLASSIFIER :
          The goal of using a Decision Tree is to create a training model that can use to predict the class or value of the target variable by learning simple decision rules inferred from prior data(training data).
          
GAUSSIAN NAIVE BAYES :
          Gaussian Naïve Bayes is the extension of naïve Bayes. While other functions are used to estimate data distribution, Gaussian or normal distribution is the simplest to implement as you will need to calculate the mean and standard deviation for the training data.

BAGGED MULTINOMIAL NAIVE BAYES :
          The Multinomial Naive Bayes algorithm is a Bayesian learning approach popular in Natural Language Processing (NLP). It calculates each tag's likelihood for a given sample and outputs the tag with the greatest chance.
          
 XGBOOST CLASSIFIER :
          XGBoost Extreme Gradient Boosting, is a scalable, distributed gradient-boosted decision tree (GBDT) machine learning library. It provides parallel tree boosting and is the leading machine learning library for regression, classification, and ranking problems.
